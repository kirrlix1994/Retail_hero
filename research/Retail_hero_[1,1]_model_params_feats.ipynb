{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - join full data\n",
    "### - get cv results\n",
    "### - Validate top features number as parameter\n",
    "### - Validate model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "  \n",
    "from dstools.spark import init_spark2, pandify2\n",
    "\n",
    "from dstools.ml import yandex_mean_encoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklift.models import SoloModel, ClassTransformation, TwoModels\n",
    "from sklift.preprocess import balancer\n",
    "from sklift.metrics import uplift_at_k\n",
    "\n",
    "from causalml.inference.tree import UpliftTreeClassifier, UpliftRandomForestClassifier\n",
    "from causalml.inference.tree import uplift_tree_string, uplift_tree_plot \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('./scripts/')\n",
    "from add_functions import catb_get_feature_imp, feat_imp, make_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = init_spark2(\"ret_modeling_1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/user/kvliksak/retailhero'\n",
    "\n",
    "df_train = spark.read.csv(\n",
    "    os.path.join(data_path, 'uplift_train.csv'), \n",
    "    inferSchema=True, header=True\n",
    ").toPandas()\n",
    "\n",
    "df_test = spark.read.csv(\n",
    "    os.path.join(data_path, 'uplift_test.csv'), \n",
    "    inferSchema=True, header=True\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400162, 77)\n"
     ]
    }
   ],
   "source": [
    "sdf_feats = spark.table('ntwk_sb.fix_price_all_geo_events_delete_me_pls')\n",
    "\n",
    "df_feats = pandify2(\n",
    "    sdf_feats.drop(\n",
    "        'first_issue_date', \n",
    "        'first_redeem_date', \n",
    "        'cl_transaction_datetime_min',\n",
    "        'cl_transaction_datetime_max',\n",
    "        ), \n",
    "    cast_overrides={\n",
    "        'cl_top_lvl_1_cnt': 'float',\n",
    "        'cl_top_lvl_2_cnt': 'float',\n",
    "        'cl_top_lvl_3_cnt': 'float',\n",
    "        'cl_top_lvl_4_cnt': 'float',\n",
    "        'cl_top_prod_cnt': 'float'\n",
    "    }).toPandas()\\\n",
    "    .set_index('client_id')\n",
    "\n",
    "    \n",
    "print(df_feats.shape)\n",
    "\n",
    "df_feats.columns =\\\n",
    "    ['m' + '_' + f for f in df_feats.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New feats cnt: 77, new cat feats cnt: 23\n"
     ]
    }
   ],
   "source": [
    "all_feats_new = df_feats.columns.tolist()\n",
    "\n",
    "cat_feats_new = df_feats\\\n",
    "    .select_dtypes(include='object').columns.tolist()\n",
    "    \n",
    "print(f'New feats cnt: {len(all_feats_new)}, new cat feats cnt: {len(cat_feats_new)}')\n",
    "# New feats cnt: 59, new cat feats cnt: 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all data\n",
    "\n",
    "cat_client_cols = [\n",
    "    'cl_first_issue_date_weekday', 'cl_first_redeem_date_weekday',\n",
    "    'cl_first_issue_date_hour', 'cl_first_redeem_date_hour'\n",
    "]\n",
    "\n",
    "# object - type feats\n",
    "cl_dtypes = {\n",
    "    feat: 'object' for feat in cat_client_cols\n",
    "}\n",
    "\n",
    "df_full = pd.read_csv(\n",
    "    'data/full_features_df.csv', \n",
    "    index_col='client_id',\n",
    "    dtype=cl_dtypes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_baseline_new_tr = pd.read_csv('data/new_baseline_tr.csv', index_col=0)\n",
    "df_baseline_new_ts = pd.read_csv('data/new_baseline_ts.csv', index_col=0)\n",
    "\n",
    "df_baseline_new_tr = df_baseline_new_tr\\\n",
    "    .drop(['treatment_flg', 'target'], axis=1)\n",
    "\n",
    "df_baseline_new_tr.columns =\\\n",
    "    [ 'ex' + '_' + f for f in df_baseline_new_tr.columns.tolist()]\n",
    "    \n",
    "df_baseline_new_ts.columns =\\\n",
    "    [ 'ex' + '_' + f for f in df_baseline_new_ts.columns.tolist()]\n",
    "    \n",
    "df_baseline_new_tr = df_baseline_new_tr\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'index': 'client_id'})\n",
    "    \n",
    "df_baseline_new_ts = df_baseline_new_ts\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'index': 'client_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400162, 328)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_mod = pd.concat([\n",
    "    df_full, df_feats_maks\n",
    "], axis=1)\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\n",
    "        'index': 'client_id'\n",
    "    })\n",
    "    \n",
    "df_full_mod.shape\n",
    "# (400162, 310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200039, 479)\n"
     ]
    }
   ],
   "source": [
    "df_full_train = pd.merge(\n",
    "    df_full_mod, df_train,\n",
    "    on='client_id', how='right'\n",
    ")\n",
    "\n",
    "df_full_train = pd.merge(\n",
    "    df_full_train, df_baseline_new_tr,\n",
    "    on='client_id', how='left'\n",
    ")\n",
    "\n",
    "print(df_full_train.shape)\n",
    "# (200039, 312)\n",
    "# (200039, 462)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200123, 477)\n"
     ]
    }
   ],
   "source": [
    "df_full_test = pd.merge(\n",
    "    df_full_mod, df_test,\n",
    "    on='client_id', how='right'\n",
    ")\n",
    "\n",
    "df_full_test = pd.merge(\n",
    "    df_full_test, df_baseline_new_ts,\n",
    "    on='client_id', how='left'\n",
    ")\n",
    "\n",
    "print(df_full_test.shape)\n",
    "# (200123, 310)\n",
    "# (200123, 460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILL CAT COLS WITH NA -> 'NA'\n",
    "cat_cols_na = [\n",
    "    'cl_first_redeem_date_hour',\n",
    "    'cl_first_redeem_date_weekday']\n",
    "\n",
    "df_full_train.loc[:, cat_cols_na] = df_full_train[cat_cols_na].fillna('NA') \n",
    "df_full_test.loc[:, cat_cols_na] = df_full_test[cat_cols_na].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full_train.loc[:, cat_cols] = df_full_train[cat_cols].fillna('NA') \n",
    "df_full_test.loc[:, cat_cols] = df_full_test[cat_cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All feats cnt: 476\n",
      "Cat feats cnt: 31\n"
     ]
    }
   ],
   "source": [
    "non_feats = ['client_id', 'treatment_flg', 'target']\n",
    "\n",
    "all_feats = list(\n",
    "    set(df_full_train.columns.tolist()) -\\\n",
    "    set(non_feats)\n",
    ")\n",
    "\n",
    "cat_cols = list(\n",
    "    set(df_full_train.select_dtypes(include='object').columns) -\\\n",
    "    set(non_feats)\n",
    ")\n",
    "\n",
    "print(f'All feats cnt: {len(all_feats)}')\n",
    "print(f'Cat feats cnt: {len(cat_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cols = ['client_id', 'target', 'treatment_flg']\n",
    "\n",
    "try_feat =\\\n",
    "    [f for f in df_full_train.columns.tolist() \n",
    "     if re.match('ex_', f)]\n",
    "\n",
    "len(try_feat)\n",
    "# 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feats = df_full_train.columns.tolist() \n",
    "try_feat = list(\n",
    "    set(all_feats) -\\\n",
    "    set(id_cols)\n",
    ")\n",
    "\n",
    "len(try_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('top_all_feats.txt', 'r') as f_in:\n",
    "    top_feats = f_in.readline().split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_top = 10\n",
    "try_feat = top_feats[:n_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SET PIPELINES:\n",
    "## PREPARE DATA FOR XGB / LGBM MODEL, fit transform target_encodet on train data\n",
    "\n",
    "enc = yandex_mean_encoder(\n",
    "    columns=list(set(cat_cols).intersection(set(try_feat))), \n",
    "    alpha=100\n",
    ")\n",
    "\n",
    "xgb_est_params = {\n",
    "    'max_depth':2,\n",
    "    'learning_rate': 0.2, \n",
    "    'n_estimators': 100,\n",
    "    \n",
    "   # 'min_child_weight': 5,\n",
    "   # 'subsample': 0.6,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0,\n",
    "    \n",
    "    'booster': 'dart',\n",
    "    \n",
    "    'nthread':40,\n",
    "    'n_gpus':0,\n",
    "    'seed':10023\n",
    "}\n",
    "\n",
    "estimator = XGBClassifier(**xgb_est_params)\n",
    "\n",
    "uplift_model_cl_tr = ClassTransformation(\n",
    "    estimator=estimator\n",
    ")\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('enc', enc),\n",
    "    ('est', uplift_model_cl_tr)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catb_est_params = {\n",
    "    'depth': 1,\n",
    "    'l2_leaf_reg': 45,\n",
    "    'iterations': 1000,\n",
    "    'verbose': False, \n",
    "    'random_state': 1000, \n",
    "    'task_type': 'GPU',\n",
    "    'devices': '1'\n",
    "}\n",
    "\n",
    "estimator_catb = CatBoostClassifier(\n",
    "    cat_features=list(\n",
    "        set(cat_cols)\\\n",
    "        .intersection(set(try_feat))\n",
    "    ), **catb_est_params\n",
    ")\n",
    "\n",
    "uplift_model_cl_tr_catb = ClassTransformation(\n",
    "    estimator=estimator_catb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator_catb = CatBoostClassifier(\n",
    "    cat_features=list(set(cat_cols).intersection(set(try_feat))),\n",
    "    verbose=200, random_state=42, task_type='GPU', devices='1'\n",
    ")\n",
    "\n",
    "uplift_model_cl_tr2 = ClassTransformation(\n",
    "    estimator=estimator_catb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'learning_rate':0.03,\n",
    "    'max_depth':2,\n",
    "    'n_estimators': 200,\n",
    "    'num_leaves':20,\n",
    "    'min_data_in_leaf':3,\n",
    "    'application':'binary',\n",
    "    'subsample':0.5, \n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha':0.05,\n",
    "    'data_random_seed':42,\n",
    "    'metric':'binary_logloss',\n",
    "    'max_bin':416,\n",
    "    'bagging_freq':3,\n",
    "    'reg_lambda':0.05,\n",
    "    'num_leaves':20,\n",
    "    'nthread': 20,\n",
    "    'seed': 42\n",
    "    }\n",
    "\n",
    "enc = yandex_mean_encoder(\n",
    "    columns=list(set(cat_cols).intersection(set(try_feat))), \n",
    "    alpha=100\n",
    ")\n",
    "\n",
    "estimator_lgbm = LGBMClassifier(**lgbm_params, verbose=200)\n",
    "\n",
    "uplift_model_cl_tr_lgbm = ClassTransformation(\n",
    "    estimator=estimator_lgbm\n",
    ")\n",
    "\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('enc', enc),\n",
    "    ('est', uplift_model_cl_tr_lgbm)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'max_depth': 4,\n",
    "    'n_jobs': 40\n",
    "}\n",
    "\n",
    "estimator_rf = RandomForestClassifier(\n",
    "    **rf_params\n",
    ")\n",
    "\n",
    "enc = yandex_mean_encoder(\n",
    "    columns=list(set(cat_cols).intersection(set(try_feat))), \n",
    "    alpha=100\n",
    ")\n",
    "\n",
    "uplift_model_cl_tr_rf = ClassTransformation(\n",
    "    estimator=estimator_rf\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('enc', enc),\n",
    "    ('est', uplift_model_cl_tr_rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "enc = yandex_mean_encoder(\n",
    "    columns=list(set(cat_cols).intersection(set(try_feat))), \n",
    "    alpha=100\n",
    ")\n",
    "\n",
    "uplift_model_cml = UpliftRandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=4, \n",
    "    min_samples_leaf=200, \n",
    "    min_samples_treatment=50, \n",
    "    n_reg=100, \n",
    "    evaluationFunction='KL', \n",
    "    control_name='0'\n",
    ")\n",
    "\n",
    "cm_pipeline = Pipeline(steps=[\n",
    "    ('enc', enc),\n",
    "    ('est', uplift_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_feat = top_feats[:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_res_catb = make_validation(\n",
    "    df_full=df_full_train,\n",
    "    upift_model=uplift_model_cl_tr_lgbm,\n",
    "    try_feat=try_feat,\n",
    "    pipeline_flg=False,\n",
    "    n_iter=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_res_catb = make_validation(\n",
    "    df_full=df_full_train,\n",
    "    upift_model=xgb_pipeline,\n",
    "    try_feat=try_feat,\n",
    "    pipeline_flg=True,\n",
    "    n_iter=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_res = pd.DataFrame()\n",
    "cnt_top_feats = [20, 30, 50, 70, 100]\n",
    "\n",
    "for n_top in cnt_top_feats:\n",
    "    \n",
    "    print(f'Top feats: {n_top}')\n",
    "    \n",
    "    try_feat = top_feats[:n_top]\n",
    "    \n",
    "    enc = yandex_mean_encoder(\n",
    "        columns=list(set(cat_cols)\\\n",
    "                    .intersection(set(try_feat))), \n",
    "        alpha=100\n",
    "    )\n",
    "    \n",
    "    estimator_catb = CatBoostClassifier(\n",
    "        cat_features=list(\n",
    "            set(cat_cols)\\\n",
    "            .intersection(set(try_feat))\n",
    "        ), **catb_est_params\n",
    "    )\n",
    "\n",
    "    uplift_model_cl_tr_catb = ClassTransformation(\n",
    "        estimator=estimator_catb\n",
    "    )\n",
    "    \n",
    "    xgb_pipeline = Pipeline(steps=[\n",
    "        ('enc', enc),\n",
    "        ('est', uplift_model_cl_tr)\n",
    "    ])\n",
    "    \n",
    "    lgbm_pipeline = Pipeline(steps=[\n",
    "        ('enc', enc),\n",
    "        ('est', uplift_model_cl_tr_lgbm)\n",
    "    ])\n",
    "    \n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('enc', enc),\n",
    "        ('est', uplift_model_cl_tr_rf)\n",
    "    ])\n",
    "    \n",
    "    val_res_catb = make_validation(\n",
    "        df_full=df_full_train,\n",
    "        upift_model=uplift_model_cl_tr_catb,\n",
    "        try_feat=try_feat,\n",
    "        pipeline_flg=False,\n",
    "        n_iter=5\n",
    "    )\n",
    "    \n",
    "    val_res_xgb = make_validation(\n",
    "        df_full=df_full_train,\n",
    "        upift_model=xgb_pipeline,\n",
    "        try_feat=try_feat,\n",
    "        pipeline_flg=True,\n",
    "        n_iter=5\n",
    "    )\n",
    "    \n",
    "    val_res_lgbm = make_validation(\n",
    "        df_full=df_full_train,\n",
    "        upift_model=lgbm_pipeline,\n",
    "        try_feat=try_feat,\n",
    "        pipeline_flg=True,\n",
    "        n_iter=5\n",
    "    )\n",
    "    \n",
    "    val_res_catb_df =\\\n",
    "    pd.DataFrame(val_res_catb).T\n",
    "    \n",
    "    val_res_xgb_df =\\\n",
    "    pd.DataFrame(val_res_xgb).T\n",
    "    \n",
    "    val_res_lgbm_df =\\\n",
    "    pd.DataFrame(val_res_lgbm).T\n",
    "    \n",
    "#     val_res_rf_df =\\\n",
    "#     pd.DataFrame(val_res_rf).T\n",
    "    \n",
    "    out_res.append({\n",
    "        'n_top': n_top,\n",
    "        'score_catb': val_res_catb_df['score_val'].mean(),\n",
    "        'score_xgb': val_res_xgb_df['score_val'].mean(),\n",
    "        'score_lgbm': val_res_lgbm_df['score_val'].mean()\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    print(f\"VAL MEAN: {val_res_catb_df['score_val'].mean():.5f} +- {val_res_catb_df['score_val'].std():.5f}\")\n",
    "    print(f\"VAL MEAN: {val_res_xgb_df['score_val'].mean():.5f} +- {val_res_xgb_df['score_val'].std():.5f}\")\n",
    "    print(f\"VAL MEAN: {val_res_lgbm_df['score_val'].mean():.5f} +- {val_res_lgbm_df['score_val'].std():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top feats: 100\n",
      "Iteration number: 1\n",
      "Iteration number: 2\n",
      "Iteration number: 3\n",
      "Iteration number: 4\n",
      "Iteration number: 5\n",
      "VAL MEAN: 0.08062 +- 0.00401\n",
      "Top feats: 110\n",
      "Iteration number: 1\n",
      "Iteration number: 2\n",
      "Iteration number: 3\n",
      "Iteration number: 4\n",
      "Iteration number: 5\n",
      "VAL MEAN: 0.08109 +- 0.00743\n",
      "Top feats: 120\n",
      "Iteration number: 1\n",
      "Iteration number: 2\n",
      "Iteration number: 3\n",
      "Iteration number: 4\n",
      "Iteration number: 5\n",
      "VAL MEAN: 0.08162 +- 0.00726\n",
      "Top feats: 130\n",
      "Iteration number: 1\n",
      "Iteration number: 2\n",
      "Iteration number: 3\n",
      "Iteration number: 4\n",
      "Iteration number: 5\n",
      "VAL MEAN: 0.08147 +- 0.00708\n",
      "Top feats: 140\n",
      "Iteration number: 1\n",
      "Iteration number: 2\n",
      "Iteration number: 3\n",
      "Iteration number: 4\n",
      "Iteration number: 5\n",
      "VAL MEAN: 0.08129 +- 0.00741\n"
     ]
    }
   ],
   "source": [
    "out_res = pd.DataFrame()\n",
    "cnt_top_feats = [100, 110, 120, 130, 140]\n",
    "\n",
    "for n_top in cnt_top_feats:\n",
    "    \n",
    "    print(f'Top feats: {n_top}')\n",
    "    \n",
    "    try_feat = top_feats[:n_top]\n",
    "        \n",
    "    estimator_catb = CatBoostClassifier(\n",
    "        cat_features=list(\n",
    "            set(cat_cols)\\\n",
    "            .intersection(set(try_feat))\n",
    "        ), **catb_est_params\n",
    "    )\n",
    "\n",
    "    uplift_model_cl_tr_catb = ClassTransformation(\n",
    "        estimator=estimator_catb\n",
    "    )\n",
    "    \n",
    "    val_res_catb = make_validation(\n",
    "        df_full=df_full_train,\n",
    "        upift_model=uplift_model_cl_tr_catb,\n",
    "        try_feat=try_feat,\n",
    "        pipeline_flg=False,\n",
    "        n_iter=5\n",
    "    )\n",
    "     \n",
    "    val_res_catb_df =\\\n",
    "    pd.DataFrame(val_res_catb).T\n",
    "    \n",
    "    out_res.append({\n",
    "        'n_top': n_top,\n",
    "        'score_catb': val_res_catb_df['score_val'].mean(),\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    print(f\"VAL MEAN: {val_res_catb_df['score_val'].mean():.5f} +- {val_res_catb_df['score_val'].std():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_full_train.loc[:,'treatment_flg'] = df_full_train['treatment_flg'].astype(str)\n",
    "\n",
    "val_res_catb = make_validation(\n",
    "    df_full=df_full_train,\n",
    "    upift_model=uplift_model_cl_tr_lgbm,\n",
    "    try_feat=try_feat,\n",
    "    pipeline_flg=False,\n",
    "    n_iter=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full_train.loc[:,'treatment_flg'] =\\\n",
    "    df_full_train['treatment_flg'].astype(str)\n",
    "\n",
    "val_res_catb = make_validation(\n",
    "    df_full=df_full_train.values,\n",
    "    upift_model=uplift_model_cml,\n",
    "    try_feat=try_feat,\n",
    "    pipeline_flg=False,\n",
    "    n_iter=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_res_catb = make_validation(\n",
    "    df_full=df_full_train,\n",
    "    upift_model=uplift_model_cl_tr_rf,\n",
    "    try_feat=try_feat,\n",
    "    pipeline_flg=False,\n",
    "    n_iter=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number: 1\n",
      "Iteration number: 2\n",
      "Iteration number: 3\n",
      "Iteration number: 4\n",
      "Iteration number: 5\n"
     ]
    }
   ],
   "source": [
    "val_res_catb = make_validation(\n",
    "    df_full=df_full_train,\n",
    "    upift_model=my_pipeline,\n",
    "    try_feat=try_feat,\n",
    "    pipeline_flg=True,\n",
    "    n_iter=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIT ON WHOLE TRAIN DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift_model_cl_tr_catb.fit(\n",
    "    df_full_train[try_feat], \n",
    "    df_full_train['target'],\n",
    "    df_full_train['treatment_flg']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200123, 1)\n"
     ]
    }
   ],
   "source": [
    "pred_test = uplift_model_cl_tr_catb.predict(df_full_test[try_feat])\n",
    "\n",
    "df_submit = df_full_test\\\n",
    "    .set_index('client_id')\\\n",
    "    .assign(uplift=pred_test)[['uplift']]\n",
    "\n",
    "print(df_submit.shape)\n",
    "df_submit.head(2)\n",
    "\n",
    "df_submit.to_csv('submissions/sub17_catb_1-1000_ex_cl_tr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id,uplift\r\n",
      "000048b7a6,0.05446345569856792\r\n",
      "000073194a,0.04197991583015659\r\n",
      "00007c7133,0.037999595985255485\r\n",
      "00007f9014,0.023304079208585238\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 submissions/sub17_catb_1-1000_ex_cl_tr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_feats = catb_get_feature_imp(\n",
    "    uplift_model_cl_tr2.estimator,\n",
    "    uplift_model_cl_tr2.estimator.feature_names_,\n",
    "    n_top=1000\n",
    ")['feat'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('top_all_feats.txt', 'w') as f_out:\n",
    "    f_out.write(';'.join(top_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOCAL RESEULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN MEAN: 0.11617 +- 0.00349\n",
      "VAL MEAN: 0.07917 +- 0.00538\n"
     ]
    }
   ],
   "source": [
    "val_res_catb_df =\\\n",
    "    pd.DataFrame(val_res_catb).T\n",
    "\n",
    "print(f\"TRAIN MEAN: {val_res_catb_df['score_tr'].mean():.5f} +- {val_res_catb_df['score_tr'].std():.5f}\")\n",
    "\n",
    "print(f\"VAL MEAN: {val_res_catb_df['score_val'].mean():.5f} +- {val_res_catb_df['score_val'].std():.5f}\")\n",
    "\n",
    "# Mask 77 feats, catb / 2 / 800\n",
    "# 0.07803 0.00648\n",
    "\n",
    "# All 260 all feats, catb / 2 / 800\n",
    "# 0.07878 0.00477\n",
    "\n",
    "# ex 150 feats, catb / 2 / 800\n",
    "# 0.08046 0.00631\n",
    "\n",
    "# lgbm 150\n",
    "#VAL MEAN: 0.08052 +- 0.00372\n",
    "\n",
    "#TRAIN MEAN: 0.11686 +- 0.00302\n",
    "#VAL MEAN: 0.07917 +- 0.00538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VALIDATE PIPELINE PARAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_res = []\n",
    "\n",
    "xgb_try_params = [\n",
    "  (1, 10, 1),\n",
    "  (2, 20, 0.5),\n",
    "  (2, 100, 0.5),\n",
    "  (2, 200, 0.4),\n",
    "  (3, 100, 0.5)  \n",
    "]\n",
    "\n",
    "for param in xgb_try_params:\n",
    "    d, n, eta = param[0], param[1], param[2]\n",
    "    print(f'Parms: {param}')\n",
    "\n",
    "    xgb_est_params = {\n",
    "        'max_depth':d, \n",
    "        'learning_rate':eta, \n",
    "        'n_estimators':n,\n",
    "        'nthread':50,\n",
    "        'n_gpus':0,\n",
    "        'seed':0\n",
    "    }\n",
    "\n",
    "    xgb_est = XGBClassifier(**xgb_est_params)\n",
    "\n",
    "    uplift_tmp_model_xgb_cl_tr = ClassTransformation(\n",
    "        estimator=xgb_est\n",
    "    )\n",
    "    \n",
    "    val_tmp = make_validation(\n",
    "        df_full=df_full_train,\n",
    "        upift_model=uplift_tmp_model_xgb_cl_tr,\n",
    "        try_feat=try_feat,\n",
    "        n_iter=20\n",
    "    )\n",
    "    \n",
    "    val_res_df =\\\n",
    "        pd.DataFrame(val_tmp).T\n",
    "    \n",
    "    mean = np.round(val_res_df['score_val'].mean(), 5)\n",
    "    std = np.round(val_res_df['score_val'].std(), 5)\n",
    "    print(f'Mean: {mean}, Std: {std}\\n')\n",
    "          \n",
    "    out_res.append(\n",
    "        [param, (mean, std)]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "income_py37_tmp",
   "language": "python",
   "name": "income_py37_tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
